{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pregunta_3_ann_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BH5qICi2jb5y",
        "outputId": "d4f3551b-ff58-4432-8e1b-cc8d89a39fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "#csv desde drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0HuoKOpHl0XY",
        "outputId": "cc3f2a92-2e06-449f-c852-76c1d50beeb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_J8_BgJNjrwx"
      },
      "source": [
        "## 3. *Encoder-Decoder* sobre Texto\n",
        "\n",
        "Trabajos recientes en redes neuronales han demostrado que se puede aplicar a problemas bastante complejos gracias a la flexibilidad la definición de las redes, además de que se pueden adaptar a distintos tipos de datos brutos (dominios). Con el objetivo de explorar el enfoque anterior de *traducción* de algun tipo de dato, en esta sección deberá realizarlo con texto para traducción de un lenguaje humano a otro (e.g. inglés a alemán, chino a ruso)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3bpddwLRlmkR",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"drive/My Drive/Colab Notebooks/por.txt\", sep=\"\\t\", names=[\"Source\",\"Target\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "18ov-iPJl81p"
      },
      "source": [
        "> a) Visualice los datos ¿Qué es la entrada y qué es la salida? Comente sobre los múltiples significados/sinónimos que puede tener una palabra al ser traducida y cómo propondría arreglar eso. *se espera que pueda implementarlo*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bxMZv99Cl3Ik",
        "outputId": "8746c5bd-cfd1-4543-cd28-c98838eb369a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vai.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vá.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Oi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corre!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corram!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Corre!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Corram!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Quem?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Source   Target\n",
              "0    Go.     Vai.\n",
              "1    Go.      Vá.\n",
              "2    Hi.      Oi.\n",
              "3   Run!   Corre!\n",
              "4   Run!   Corra!\n",
              "5   Run!  Corram!\n",
              "6   Run.   Corre!\n",
              "7   Run.   Corra!\n",
              "8   Run.  Corram!\n",
              "9   Who?    Quem?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N1JBeAONma4h"
      },
      "source": [
        "La entrada del dataset corresponde a la frase o palabra escrita en ingles y el objetivo o salida corresponde a la traducción de lo anterior al idioma que se desea trabajar, en este caso portugues.\n",
        "\n",
        "Al inicio del dataset se pueden ver unicamente palabras junto con su traducción explicita, se puede notar ademas que existen palabras repetidas en ingles que se traducen de una manera distinta, esto se debe a que el ingles no posee una conjugación explicita en la palabra como es el caso del español o el portuges, sino que se le da un contexto con el resto de la oración. Se espera que el encoder tenga problemas al traducir frases con dichas palabras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "62DwDH0MmX2K",
        "outputId": "ab48171b-1711-4144-e15a-70b1600a2521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>135666</th>\n",
              "      <td>The Tatoeba Project, which can be found online...</td>\n",
              "      <td>O Projeto Tatoeba, que se pode encontrar on-li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135667</th>\n",
              "      <td>No matter how much you try to convince people ...</td>\n",
              "      <td>Não importa o quanto você tenta convencer os o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135668</th>\n",
              "      <td>Some movies make such an impact that one never...</td>\n",
              "      <td>Alguns filmes são tão marcantes que jamais nos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135669</th>\n",
              "      <td>A child who is a native speaker usually knows ...</td>\n",
              "      <td>Uma criança que é falante nativa geralmente sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135670</th>\n",
              "      <td>We recommend adding sentences and translations...</td>\n",
              "      <td>Recomendamos acrescentar frases e traduções na...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Source                                             Target\n",
              "135666  The Tatoeba Project, which can be found online...  O Projeto Tatoeba, que se pode encontrar on-li...\n",
              "135667  No matter how much you try to convince people ...  Não importa o quanto você tenta convencer os o...\n",
              "135668  Some movies make such an impact that one never...  Alguns filmes são tão marcantes que jamais nos...\n",
              "135669  A child who is a native speaker usually knows ...  Uma criança que é falante nativa geralmente sa...\n",
              "135670  We recommend adding sentences and translations...  Recomendamos acrescentar frases e traduções na..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NTyPtK2wmMPc"
      },
      "source": [
        "Cuando se analizan los datos al final del conjunto se puede ver que ya se esta trabajando con oraciones y no unicamente con palabras simples, se espera que estos ejemplos permitan a la red neuronal aprender a reconocer un poco el contexto en el cual se esta utilizando la palabra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZlJXIT1pnu4Q"
      },
      "source": [
        "> b) Realice un pre-procesamiento a los textos como se acostumbra para eliminar símbolos inecesarios u otras cosas que estime conveniente, comente sobre la importancia de éste paso. Además de ésto deberá agregar un símbolo al final de la sentencia *target* para indicar un \"alto\" cuando la red neuronal necesite aprender a generar una sentencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XZqprTLpl3LV",
        "colab": {}
      },
      "source": [
        "table = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "def clean_text(text, where=None):\n",
        "    \"\"\" OJO: Sin eliminar el significado de las palabras.\"\"\"\n",
        "    text = text.lower()\n",
        "    tokenize_text = text.split()\n",
        "    tokenize_text = [word.translate(table) for word in tokenize_text]#eliminar puntuacion\n",
        "    tokenize_text = [word for word in tokenize_text if word.isalpha()] #remove numbers\n",
        "    if where == 'target':\n",
        "        tokenize_text = [\"BOS\"] + tokenize_text + [\"EOS\"] \n",
        "    return tokenize_text\n",
        "\n",
        "  \n",
        "texts_input = list(df['Source'].apply(clean_text))\n",
        "texts_output = list(df['Target'].apply(clean_text, where='target'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4Uq4O2NcoR9U"
      },
      "source": [
        "> Cree un conjunto de validación y de pruebas fijos de $N_{exp} = 10000$ datos ¿Cuántos datos quedan para entrenar? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kFsSmWJ9ogst",
        "colab": {}
      },
      "source": [
        "N_exp = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TiYlkP23l3OW",
        "colab": {}
      },
      "source": [
        "X_train_l, X_test_l, Y_train_l, Y_test_l = train_test_split(texts_input, texts_output,\n",
        "                                                            test_size=N_exp, random_state=22)\n",
        "X_train_l, X_val_l, Y_train_l, Y_val_l = train_test_split(X_train_l, Y_train_l, \n",
        "                                                          test_size=N_exp, random_state=22)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jWt6PF1El3Qs",
        "outputId": "e60a9daa-256c-4500-e7ab-626a28308eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(X_train_l)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115671"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Nj5BGP0otYS"
      },
      "source": [
        "Luego de haber generado el cconjunto de testing y validación aún quedan 115671 ejemplos para entrenar el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jRwaQUY4o52h"
      },
      "source": [
        "> *Recuerde que si no puede procesar los datos de entrenamiento adecuadamente siempre puede muestrear en base a la capacidad de cómputo que posea*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWv7nkZEo8vo"
      },
      "source": [
        "> c) Genere un vocabulario, **desde el conjunto de entrenamiento**, sobre las palabras a recibir y generar en la traducción, esto es codificarlas a un valor entero que servirá para que la red las vea en una representación útil a procesar, *comience desde el 1 debido a que el cero será utilizado más adelante*. Para reducir el vocabulario considere las palabras que aparecen un mínimo de *min_count* veces en todo los datos, se aconseja un valor de 3. Comente sobre la importancia de ésto al reducir el vocabulario ¿De qué tamaño es el vocabulario de entrada y salida? ¿La diferencia de ésto podría ser un factor importante?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hn54Zioel3Te",
        "colab": {}
      },
      "source": [
        "def create_vocab(texts, min_count=1):\n",
        "    count_vocab = {}\n",
        "    for sentence in texts:\n",
        "        for word in sentence:\n",
        "            if word not in count_vocab:\n",
        "                count_vocab[word] = 1\n",
        "            else:\n",
        "                count_vocab[word] += 1\n",
        "    return [word for word,count in count_vocab.items() if count >= min_count]\n",
        "  \n",
        "vocab_source = create_vocab(X_train_l, min_count=3)\n",
        "word2idx_s = {w: i+1 for i, w in enumerate(vocab_source)} #index (i+1) start from 1,2,3,...\n",
        "idx2word_s = {i+1: w for i, w in enumerate(vocab_source)}\n",
        "n_words_s = len(vocab_source)\n",
        "vocab_target = create_vocab(Y_train_l, min_count=3)\n",
        "word2idx_t = {w: i+1 for i, w in enumerate(vocab_target)}  #Converting text to numbers\n",
        "idx2word_t = {i+1: w for i, w in enumerate(vocab_target)}\n",
        "n_words_t = len(vocab_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cizs2bRqpyxK"
      },
      "source": [
        "Dado que existe una gran cantidad de palabras dentro del vocabulario y la memoria del sistema que se utilice no es ilimitada es necesario reducir el tamaño para poder trabajar con el dataset, ademas palabras que aparescan menos de una determinada cantidad de veces pueden considerarse como poco relevantes para la traducción del texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "47NOdPeWpt7d",
        "outputId": "9d59ff32-4c2f-48b3-8acd-13c113720502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(\"Tamaño de palabras en origen:\",n_words_s)\n",
        "print(\"\\nTamaño de palabras en destino\",n_words_t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamaño de palabras en origen: 5954\n",
            "\n",
            "Tamaño de palabras en destino 8761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qonri4Saprhl"
      },
      "source": [
        "El tamaño del conjunto de palabras de origen es de 5954 palabras, mientras que el destino es de 8760, esto se debe a lo comentado anteriormente referenciando a que el ingles obtiene la conjugación de una palabra en base al contexto en el cual se esta hablando y no explicitamente en la forma en que se escribe.\n",
        "\n",
        "Esto, en opinión propia, puede afectar negativamente a la red, puesto que sin el contexto adecuado una red podría traducir una palabra de multiples maneras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jJDsAJkArZMK"
      },
      "source": [
        "> Ahora codifique las palabras a los números indexados con el vocabulario. Recuerde que si una palabra en los otros conjuntos, o en el mismo de entrenamiento, no aparece en el vocabulario no se podrá generar una codificación, por lo que será **ignorada** ¿Cómo se podría evitar ésto?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U6nzVB-Ol3WJ",
        "colab": {}
      },
      "source": [
        "\"\"\" Source/input data \"\"\"\n",
        "dataX_train = [[word2idx_s[word] for word in sent if word in word2idx_s] for sent in X_train_l]\n",
        "dataX_val = [[word2idx_s[word] for word in sent if word in word2idx_s] for sent in X_val_l]\n",
        "dataX_test = [[word2idx_s[word] for word in sent if word in word2idx_s] for sent in X_test_l]\n",
        "\n",
        "\"\"\" Target/output data \"\"\"\n",
        "dataY_train = [[word2idx_t[word] for word in sent if word in word2idx_t] for sent in Y_train_l]\n",
        "dataY_val = [[word2idx_t[word] for word in sent if word in word2idx_t] for sent in Y_val_l] \n",
        "dataY_test = [[word2idx_t[word] for word in sent if word in word2idx_t] for sent in Y_test_l] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3XRY-QiBsSXA"
      },
      "source": [
        "> d) Debido al largo variable de los textos de entrada y salida será necesario estandarizar ésto para poder trabajar de manera más cómoda en Keras, *cada texto (entrada y salida) pueden tener distinto largo máximo*. Comente sobre la decisión del tipo de *padding*, *pre o post* ¿Qué sucede al variar el largo máximo de instantes de tiempo para procesar en cada parte del modelo (entrada y salida)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F5BdzJFml3Ys",
        "outputId": "3fee06a2-21f7-4941-e550-ac534f36cfab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\" INPUT DATA (Origin language) \"\"\"\n",
        "max_inp_length = max([max(map(len,dataX_train)), max(map(len,dataX_val)), max(map(len,dataX_test))])\n",
        "print(\"Largo max inp: \",max_inp_length)\n",
        "word2idx_s[\"*\"] = 0 #padding symbol\n",
        "idx2word_s[0] = \"*\"\n",
        "n_words_s += 1  \n",
        "X_train = sequence.pad_sequences(dataX_train, maxlen=max_inp_length, padding='post', value=word2idx_s[\"*\"])\n",
        "X_val = sequence.pad_sequences(dataX_val, maxlen=max_inp_length, padding='post', value=word2idx_s[\"*\"])\n",
        "X_test = sequence.pad_sequences(dataX_test, maxlen=max_inp_length, padding='post', value=word2idx_s[\"*\"])\n",
        "\n",
        "\"\"\" OUTPUT DATA (Destination language) \"\"\"\n",
        "max_out_length = max([max(map(len,dataY_train)), max(map(len,dataY_val)), max(map(len,dataY_test))])\n",
        "print(\"Largo max out: \",max_out_length)\n",
        "word2idx_t[\"*\"] = 0 #padding symbol\n",
        "idx2word_t[0] = \"*\"\n",
        "n_words_t += 1  \n",
        "Y_train = sequence.pad_sequences(dataY_train, maxlen=max_out_length, padding='post', value=word2idx_t[\"*\"])\n",
        "Y_val = sequence.pad_sequences(dataY_val, maxlen=max_out_length, padding='post', value=word2idx_t[\"*\"])\n",
        "Y_test = sequence.pad_sequences(dataY_test, maxlen=max_out_length, padding='post', value=word2idx_t[\"*\"])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Largo max inp:  35\n",
            "Largo max out:  35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZFSKSmxStx06"
      },
      "source": [
        "> e) Para evitar que la red obtenga una ganancia por imitar/predecir el símbolo de *padding* que está bastante presente en los datos coloque un peso sobre éste clase, con valor 0, así se evita que tenga impacto en la función objetivo. Ya que *keras* no soporta directamente ésto en series de tiempo coloque el peso a cada instante de tiempo de cada dato de entrenamiento dependiendo de su clase. Comente sobre alguna otra forma en que se podría manejar el evitar que la red prediga en mayoría el símbolo de *padding*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vB0zWIozl3bi",
        "colab": {}
      },
      "source": [
        "c_weights = np.ones(n_words_t)\n",
        "c_weights[0] = 0 #padding class masked\n",
        "sample_weight = np.zeros(Y_train.shape)\n",
        "for i in range(sample_weight.shape[0]):\n",
        "    sample_weight[i] = c_weights[Y_train[i,:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pjCQm57-8uW",
        "colab_type": "text"
      },
      "source": [
        "> f) Para lograr la tarea defina una red recurrente del tipo *encoder*-*decoder* como la que se presenta en la siguiente imágen.\n",
        "<img src=\"https://chunml.github.io/ChunML.github.io/images/projects/sequence-to-sequence/repeated_vector.png\" width=\"60%\" />\n",
        "En primer lugar defina el *Encoder* que procesara el texto de entrada y retornará un solo vector final, haciendo uso de las capas ya conocidas de *Embedding* para generar un vector denso de palabra y *GRU*, pero en su versión acelerada para GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU3HcYfF-8uX",
        "colab_type": "code",
        "outputId": "84b500fa-6802-4c8f-bb22-d379c68c8fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,CuDNNGRU, GRU\n",
        "EMBEDDING_DIM = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_words_s, output_dim=EMBEDDING_DIM, input_length=max_inp_length))\n",
        "model.add(CuDNNGRU(64, return_sequences=True))\n",
        "model.add(CuDNNGRU(128, return_sequences=False))\n",
        "#model.add(GRU(64, return_sequences=True))\n",
        "#model.add(GRU(128, return_sequences=False))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0626 17:46:41.052778 139758613624704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0626 17:46:41.088880 139758613624704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0626 17:46:41.096385 139758613624704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvtDnKXf-8ua",
        "colab_type": "text"
      },
      "source": [
        "> Luego defina la sección que conecta el largo (*timesteps*) de entrada *vs* el de salida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QSp4a8Z-8ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import RepeatVector\n",
        "model.add(RepeatVector(max_out_length)) #conection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PPTOlFS-8uc",
        "colab_type": "text"
      },
      "source": [
        "Finalmente defina el *Decoder* para generar la secuencia de salida en texto de palabras en otro idioma, a través de la función *softmax* sobre cada instante de tiempo (*timestep*). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L7J-2hR-8ud",
        "colab_type": "code",
        "outputId": "4afcb662-362c-401d-88e4-779a32e238f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "from keras.layers import GRU, TimeDistributed,Dense\n",
        "model.add(CuDNNGRU(128, return_sequences=True))\n",
        "model.add(CuDNNGRU(64, return_sequences=True))\n",
        "#model.add(GRU(64, return_sequences=True))\n",
        "#model.add(GRU(128, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(n_words_t, activation='softmax')))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 35, 100)           595500    \n",
            "_________________________________________________________________\n",
            "cu_dnngru_1 (CuDNNGRU)       (None, 35, 64)            31872     \n",
            "_________________________________________________________________\n",
            "cu_dnngru_2 (CuDNNGRU)       (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 35, 128)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_3 (CuDNNGRU)       (None, 35, 128)           99072     \n",
            "_________________________________________________________________\n",
            "cu_dnngru_4 (CuDNNGRU)       (None, 35, 64)            37248     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 35, 8762)          569530    \n",
            "=================================================================\n",
            "Total params: 1,407,718\n",
            "Trainable params: 1,407,718\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvkqB3xr-8uf",
        "colab_type": "text"
      },
      "source": [
        "> Entrene la red entre 1 a 5 *epochs*, agregando los pesos definidos sobre cada ejemplo de entrenamiento. Además de utilizar una función de pérdida que evita generar explícitamente los *one hot vector*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8DggQpE-8ug",
        "colab_type": "text"
      },
      "source": [
        "Antes de entrenar es necesario cambiar la forma del output a 3 dimensiones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs8bNE0B-8uh",
        "colab_type": "code",
        "outputId": "f5f59d03-b0cb-4403-eeaf-5516249646e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Y_train = np.reshape(Y_train, (Y_train.shape[0], max_out_length, 1))\n",
        "Y_val = np.reshape(Y_val, (Y_val.shape[0], max_out_length, 1))\n",
        "Y_test = np.reshape(Y_test, (Y_test.shape[0], max_out_length, 1))\n",
        "\n",
        "Y_train.shape\n",
        "#X_test = np.reshape(X_test, (X_test.shape[0], lstm_num_timesteps, lstm_num_features))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(115671, 35, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2lASZBg-8uj",
        "colab_type": "code",
        "outputId": "3ac53988-6c82-408f-8a0c-5db01a0fc436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', sample_weight_mode='temporal')\n",
        "model.fit(X_train, Y_train, epochs=3, batch_size=256,validation_data=(X_val, Y_val), sample_weight = sample_weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0626 17:46:43.106671 139758613624704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0626 17:46:43.137966 139758613624704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0626 17:46:43.243191 139758613624704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0626 17:46:43.954685 139758613624704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 115671 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "115671/115671 [==============================] - 50s 434us/step - loss: 5.6570 - val_loss: 12.1736\n",
            "Epoch 2/3\n",
            "115671/115671 [==============================] - 43s 373us/step - loss: 5.3583 - val_loss: 12.8971\n",
            "Epoch 3/3\n",
            "115671/115671 [==============================] - 43s 375us/step - loss: 5.2091 - val_loss: 13.4141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1bafb31dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK2AhrXMAipW",
        "colab_type": "text"
      },
      "source": [
        "> g) Debido a lo costoso de tener una red completamente recurrente para entrenar y poder experimentar, cambie el modelo que procesa el *Encoder* por una red convolucional, reduciendo el número de capas pero aumentando las neuronas. Utilice tamaños de *kernel*  igual a 5 y funciones de activaciones relu. Se agregan capas de *BatchNormalization* debido a que en el *Decoder* contamos con redes recurrentes que tienen capa activación distinta a la usada por las convoluciones. La capa de *GlobalMaxPooling1d* es lo que permite reducir toda la información extraída a un único vector, como se realizó anteriormente con *return_sequences=False*, comente sobre la ganancia o desventaja de ésto *vs* la red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNqCt5TK-8un",
        "colab_type": "code",
        "outputId": "5d72112f-fc2c-4595-9727-587e17a6a1ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "from keras.layers import Conv1D,MaxPool1D,GlobalMaxPooling1D,GlobalAveragePooling1D,BatchNormalization, InputLayer\n",
        "modelc = Sequential()\n",
        "modelc.add(Embedding(input_dim=n_words_s, output_dim=EMBEDDING_DIM, input_length=max_inp_length))\n",
        "modelc.add(Conv1D(256, 5, padding='same', activation='relu', strides=1))\n",
        "modelc.add(BatchNormalization()) #for stability\n",
        "modelc.add(Conv1D(256, 5, padding='same', activation='relu', strides=1))\n",
        "modelc.add(BatchNormalization())\n",
        "modelc.add(GlobalMaxPooling1D()) #aka to return_sequences=False\n",
        "modelc.add(RepeatVector(max_out_length)) #conection\n",
        "modelc.add(CuDNNGRU(256, return_sequences=True))\n",
        "modelc.add(TimeDistributed(Dense(n_words_t, activation='softmax')))\n",
        "modelc.compile(optimizer='adam', loss='sparse_categorical_crossentropy', sample_weight_mode='temporal')\n",
        "modelc.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 35, 100)           595500    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 35, 256)           128256    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 35, 256)           1024      \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 35, 256)           1024      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 35, 256)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_5 (CuDNNGRU)       (None, 35, 256)           394752    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 35, 8762)          2251834   \n",
            "=================================================================\n",
            "Total params: 3,700,326\n",
            "Trainable params: 3,699,302\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyRK2UeBBHGc",
        "colab_type": "text"
      },
      "source": [
        "> Entrene el modelo igual a lo presentado anteriormente pero ahora por 20 *epochs* ¿Cambian los tiempos de procesamiento y la cantidad de parámetros?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qunj7jkY-8uo",
        "colab_type": "code",
        "outputId": "9c18088c-1d18-4477-cf5f-cc4b1727a31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "modelc.fit(X_train, Y_train, epochs=20, batch_size=256,validation_data=(X_val, Y_val), sample_weight = sample_weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 115671 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "115671/115671 [==============================] - 58s 499us/step - loss: 4.8021 - val_loss: 13.2694\n",
            "Epoch 2/20\n",
            "115671/115671 [==============================] - 55s 480us/step - loss: 3.8034 - val_loss: 13.3340\n",
            "Epoch 3/20\n",
            "115671/115671 [==============================] - 56s 484us/step - loss: 3.1964 - val_loss: 13.2349\n",
            "Epoch 4/20\n",
            "115671/115671 [==============================] - 56s 486us/step - loss: 2.8064 - val_loss: 13.1902\n",
            "Epoch 5/20\n",
            "115671/115671 [==============================] - 56s 486us/step - loss: 2.5269 - val_loss: 13.1602\n",
            "Epoch 6/20\n",
            "115671/115671 [==============================] - 56s 486us/step - loss: 2.3129 - val_loss: 13.1418\n",
            "Epoch 7/20\n",
            "115671/115671 [==============================] - 56s 488us/step - loss: 2.1493 - val_loss: 13.0869\n",
            "Epoch 8/20\n",
            "115671/115671 [==============================] - 56s 487us/step - loss: 2.0186 - val_loss: 13.0770\n",
            "Epoch 9/20\n",
            "115671/115671 [==============================] - 56s 487us/step - loss: 1.9100 - val_loss: 13.0705\n",
            "Epoch 10/20\n",
            "115671/115671 [==============================] - 56s 487us/step - loss: 1.8188 - val_loss: 13.0537\n",
            "Epoch 11/20\n",
            "115671/115671 [==============================] - 56s 487us/step - loss: 1.7398 - val_loss: 13.0483\n",
            "Epoch 12/20\n",
            "115671/115671 [==============================] - 56s 487us/step - loss: 1.6727 - val_loss: 13.0548\n",
            "Epoch 13/20\n",
            "115671/115671 [==============================] - 56s 487us/step - loss: 1.6097 - val_loss: 13.0451\n",
            "Epoch 14/20\n",
            "115671/115671 [==============================] - 56s 486us/step - loss: 1.5646 - val_loss: 13.0613\n",
            "Epoch 15/20\n",
            "115671/115671 [==============================] - 56s 486us/step - loss: 1.5136 - val_loss: 13.0550\n",
            "Epoch 16/20\n",
            "115671/115671 [==============================] - 56s 486us/step - loss: 1.4673 - val_loss: 13.0386\n",
            "Epoch 17/20\n",
            "115671/115671 [==============================] - 56s 486us/step - loss: 1.4351 - val_loss: 13.0389\n",
            "Epoch 18/20\n",
            "115671/115671 [==============================] - 56s 486us/step - loss: 1.3944 - val_loss: 13.0481\n",
            "Epoch 19/20\n",
            "115671/115671 [==============================] - 56s 485us/step - loss: 1.3647 - val_loss: 13.0426\n",
            "Epoch 20/20\n",
            "115671/115671 [==============================] - 56s 486us/step - loss: 1.3290 - val_loss: 13.0411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1baf105438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9lac8KvBjoE",
        "colab_type": "text"
      },
      "source": [
        "> h) Visualice lo aprendido por el modelo sobre algunos datos del conjunto de entrenamiento y validación, comente lo observado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asg7sSwd-8uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_words(y_indexs, data=\"target\"):\n",
        "    \"\"\" Predict until '-#anvorgesa-' is seen \"\"\"\n",
        "    return_val = []\n",
        "    for indx_word in y_indexs:\n",
        "        if indx_word != 0: #start to predict\n",
        "            return_val.append(np.squeeze(indx_word))\n",
        "            if data == \"target\": #if target is predicting\n",
        "                if indx_word == word2idx_t[\"EOS\"]:\n",
        "                    return return_val                \n",
        "    return return_val\n",
        "  \n",
        "n_s = 30\n",
        "idx = np.random.choice(np.arange(Y_test.shape[0]), size=n_s, replace=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okD-UpdX-8ur",
        "colab_type": "code",
        "outputId": "b7914d44-cbd1-42bc-f097-efb9da598f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"For the first model:\")\n",
        "Y_test_pred = model.predict_classes(X_test[idx])\n",
        "for i, n_sampled in enumerate(idx):\n",
        "    text_input = [idx2word_s[p] for p in predict_words(X_test[n_sampled], data=\"source\")]\n",
        "    print(\"\\nText source: \", ' '.join(text_input))\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_test[n_sampled,:,0], data=\"target\")]\n",
        "    print(\"Text target true: \", ' '.join( text_real))\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_test_pred[i], data=\"target\")]\n",
        "    print(\"Text target predicted: \", ' '.join(text_sampled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the first model:\n",
            "\n",
            "Text source:  will get lower\n",
            "Text target true:  BOS as EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  hes shorter than tom\n",
            "Text target true:  BOS ele é mais baixo do que tom EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  wait in here\n",
            "Text target true:  BOS espere aqui EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  youre bluffing\n",
            "Text target true:  BOS vocês estão blefando EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  they bought a car\n",
            "Text target true:  BOS eles compraram um carro EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  fog has limited to meters\n",
            "Text target true:  BOS o a a metros EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  she said that she was eager to go there\n",
            "Text target true:  BOS ela disse que estava ansiosa para ir lá EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  is the of life\n",
            "Text target true:  BOS a variedade é o da vida EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  we are looking forward to hearing about your trip\n",
            "Text target true:  BOS estamos esperando ouvir sobre a sua viagem EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  stop changing the subject\n",
            "Text target true:  BOS pare de mudar de assunto EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  i didnt even know your name\n",
            "Text target true:  BOS eu nem sequer sabia o seu nome EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  tom looked at the sky\n",
            "Text target true:  BOS tom olhou para o céu EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  tom was waiting over there for you but i dont see him now\n",
            "Text target true:  BOS tom estava esperando por você mas eu não estou vendo ele agora EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  tom didnt show up for work yesterday\n",
            "Text target true:  BOS tom não veio trabalhar ontem EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  tom ate his with his salad fork\n",
            "Text target true:  BOS por engano o tomás comeu a entrada com o garfo da salada EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  i dont want to hurt your feelings\n",
            "Text target true:  BOS eu não quero ferir os seus sentimentos EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  if tom had stayed in his hometown he never wouldve met mary\n",
            "Text target true:  BOS se o tom tivesse ficado em sua cidade natal ele nunca teria conhecido a mary EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  tom was unable to hold a job or live by himself\n",
            "Text target true:  BOS tom era incapaz de se manter num emprego e de viver sozinho EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  you have betrayed us\n",
            "Text target true:  BOS você nos traiu EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  have you ever been to\n",
            "Text target true:  BOS você já esteve em EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  id like a hot tea with honey\n",
            "Text target true:  BOS gostaria de um chá quente com mel EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  toms wife keeps him grounded\n",
            "Text target true:  BOS a esposa do tom o mantém de castigo EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  tom did it all\n",
            "Text target true:  BOS tom fez tudo EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  tom got the job he wanted\n",
            "Text target true:  BOS tom conseguiu o emprego que EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  we need a leader\n",
            "Text target true:  BOS nós precisamos de um líder EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  i dont want to make anyone unhappy\n",
            "Text target true:  BOS eu não quero fazer com que ninguém se sinta infeliz EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  are you finished\n",
            "Text target true:  BOS você terminou EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  get your coat\n",
            "Text target true:  BOS pegue o seu casaco EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  whatre you doing in my room\n",
            "Text target true:  BOS o que você está fazendo no meu quarto EOS\n",
            "Text target predicted:  BOS EOS\n",
            "\n",
            "Text source:  ill never give you permission to do that\n",
            "Text target true:  BOS nunca te darei permissão para fazer isso EOS\n",
            "Text target predicted:  BOS EOS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy8sDYbH-8ut",
        "colab_type": "code",
        "outputId": "54574ad4-8917-4b0f-db24-d1a0badd3f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"For the convolutional model:\")\n",
        "Y_test_pred = modelc.predict_classes(X_test[idx] )\n",
        "for i, n_sampled in enumerate(idx):\n",
        "    text_input = [idx2word_s[p] for p in predict_words(X_test[n_sampled], data=\"source\")]\n",
        "    print(\"\\nText source: \", ' '.join(text_input))\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_test[n_sampled,:,0], data=\"target\")]\n",
        "    print(\"Text target true: \", ' '.join( text_real))\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_test_pred[i], data=\"target\")]\n",
        "    print(\"Text target predicted: \", ' '.join(text_sampled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the convolutional model:\n",
            "\n",
            "Text source:  will get lower\n",
            "Text target true:  BOS as EOS\n",
            "Text target predicted:  BOS vai pegar EOS\n",
            "\n",
            "Text source:  hes shorter than tom\n",
            "Text target true:  BOS ele é mais baixo do que tom EOS\n",
            "Text target predicted:  BOS ele é mais do do tom tom EOS\n",
            "\n",
            "Text source:  wait in here\n",
            "Text target true:  BOS espere aqui EOS\n",
            "Text target predicted:  BOS espere aqui EOS\n",
            "\n",
            "Text source:  youre bluffing\n",
            "Text target true:  BOS vocês estão blefando EOS\n",
            "Text target predicted:  BOS você está blefando EOS\n",
            "\n",
            "Text source:  they bought a car\n",
            "Text target true:  BOS eles compraram um carro EOS\n",
            "Text target predicted:  BOS eles um carro carro EOS\n",
            "\n",
            "Text source:  fog has limited to meters\n",
            "Text target true:  BOS o a a metros EOS\n",
            "Text target predicted:  BOS a metros metros metros EOS\n",
            "\n",
            "Text source:  she said that she was eager to go there\n",
            "Text target true:  BOS ela disse que estava ansiosa para ir lá EOS\n",
            "Text target predicted:  BOS ela disse que que ir ir ir EOS\n",
            "\n",
            "Text source:  is the of life\n",
            "Text target true:  BOS a variedade é o da vida EOS\n",
            "Text target predicted:  BOS a é a vida vida EOS\n",
            "\n",
            "Text source:  we are looking forward to hearing about your trip\n",
            "Text target true:  BOS estamos esperando ouvir sobre a sua viagem EOS\n",
            "Text target predicted:  BOS nós temos de sobre a a sua sua sua sua sua EOS\n",
            "\n",
            "Text source:  stop changing the subject\n",
            "Text target true:  BOS pare de mudar de assunto EOS\n",
            "Text target predicted:  BOS pare de mudar mudar assunto EOS\n",
            "\n",
            "Text source:  i didnt even know your name\n",
            "Text target true:  BOS eu nem sequer sabia o seu nome EOS\n",
            "Text target predicted:  BOS eu nem sei sei o seu nome EOS\n",
            "\n",
            "Text source:  tom looked at the sky\n",
            "Text target true:  BOS tom olhou para o céu EOS\n",
            "Text target predicted:  BOS tom olhou olhou o céu EOS\n",
            "\n",
            "Text source:  tom was waiting over there for you but i dont see him now\n",
            "Text target true:  BOS tom estava esperando por você mas eu não estou vendo ele agora EOS\n",
            "Text target predicted:  BOS tom estava esperando ali esperando eu eu eu agora agora agora agora agora agora agora agora agora agora EOS\n",
            "\n",
            "Text source:  tom didnt show up for work yesterday\n",
            "Text target true:  BOS tom não veio trabalhar ontem EOS\n",
            "Text target predicted:  BOS tom não foi ontem ontem ontem EOS\n",
            "\n",
            "Text source:  tom ate his with his salad fork\n",
            "Text target true:  BOS por engano o tomás comeu a entrada com o garfo da salada EOS\n",
            "Text target predicted:  BOS tom comeu as as as as as com com EOS\n",
            "\n",
            "Text source:  i dont want to hurt your feelings\n",
            "Text target true:  BOS eu não quero ferir os seus sentimentos EOS\n",
            "Text target predicted:  BOS eu não quis os os sentimentos EOS\n",
            "\n",
            "Text source:  if tom had stayed in his hometown he never wouldve met mary\n",
            "Text target true:  BOS se o tom tivesse ficado em sua cidade natal ele nunca teria conhecido a mary EOS\n",
            "Text target predicted:  BOS se teria teria na na na na teria teria teria teria teria teria teria EOS\n",
            "\n",
            "Text source:  tom was unable to hold a job or live by himself\n",
            "Text target true:  BOS tom era incapaz de se manter num emprego e de viver sozinho EOS\n",
            "Text target predicted:  BOS tom era um um de um um para EOS\n",
            "\n",
            "Text source:  you have betrayed us\n",
            "Text target true:  BOS você nos traiu EOS\n",
            "Text target predicted:  BOS você nos nos EOS\n",
            "\n",
            "Text source:  have you ever been to\n",
            "Text target true:  BOS você já esteve em EOS\n",
            "Text target predicted:  BOS você já foi EOS\n",
            "\n",
            "Text source:  id like a hot tea with honey\n",
            "Text target true:  BOS gostaria de um chá quente com mel EOS\n",
            "Text target predicted:  BOS eu de um uma quente com com EOS\n",
            "\n",
            "Text source:  toms wife keeps him grounded\n",
            "Text target true:  BOS a esposa do tom o mantém de castigo EOS\n",
            "Text target predicted:  BOS tom está a de de EOS\n",
            "\n",
            "Text source:  tom did it all\n",
            "Text target true:  BOS tom fez tudo EOS\n",
            "Text target predicted:  BOS tom fez tudo tudo EOS\n",
            "\n",
            "Text source:  tom got the job he wanted\n",
            "Text target true:  BOS tom conseguiu o emprego que EOS\n",
            "Text target predicted:  BOS tom tom o emprego que ele EOS\n",
            "\n",
            "Text source:  we need a leader\n",
            "Text target true:  BOS nós precisamos de um líder EOS\n",
            "Text target predicted:  BOS nós de de do EOS\n",
            "\n",
            "Text source:  i dont want to make anyone unhappy\n",
            "Text target true:  BOS eu não quero fazer com que ninguém se sinta infeliz EOS\n",
            "Text target predicted:  BOS eu quero quero que ninguém ninguém EOS\n",
            "\n",
            "Text source:  are you finished\n",
            "Text target true:  BOS você terminou EOS\n",
            "Text target predicted:  BOS você terminou EOS\n",
            "\n",
            "Text source:  get your coat\n",
            "Text target true:  BOS pegue o seu casaco EOS\n",
            "Text target predicted:  BOS pegue o casaco EOS\n",
            "\n",
            "Text source:  whatre you doing in my room\n",
            "Text target true:  BOS o que você está fazendo no meu quarto EOS\n",
            "Text target predicted:  BOS o que você está fazendo no meu quarto EOS\n",
            "\n",
            "Text source:  ill never give you permission to do that\n",
            "Text target true:  BOS nunca te darei permissão para fazer isso EOS\n",
            "Text target predicted:  BOS eu nunca darei dar para para fazer isso EOS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYXgtU4S5bYy",
        "colab_type": "text"
      },
      "source": [
        "> i) Realice algún cambio esperando que mejore el modelo entrenado, luego vuelva a visualizar lo predicho por la red *vs* lo real. *Debido a lo costoso en entrenar puede optar por realizar solo un cambio pero que sea significativo*.  Se comentan algunas opciones para utilizar y combinar:\n",
        "* Cambiar  el *embedding* por alguno pre-entrenado\n",
        "* Agregar regularizadores\n",
        "* Asignar peso a las clases/palabras de salida\n",
        "* Cambiar *Global max pooling* por *Average max pooling*\n",
        "* Aumentar o reducir capas\n",
        "* Aumentar o reducir neuronas/unidades  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB_lrWUd5v55",
        "colab_type": "code",
        "outputId": "be3416d1-98f2-400d-ae7c-6d4a95fa2335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "modeli = Sequential()\n",
        "modeli.add(Embedding(input_dim=n_words_s, output_dim=EMBEDDING_DIM, input_length=max_inp_length))\n",
        "modeli.add(Conv1D(256, 5, padding='same', activation='relu', strides=1))\n",
        "modeli.add(BatchNormalization()) #for stability\n",
        "modeli.add(Conv1D(256, 5, padding='same', activation='relu', strides=1))\n",
        "modeli.add(BatchNormalization())\n",
        "modeli.add(Conv1D(256, 5, padding='same', activation='relu', strides=1))\n",
        "modeli.add(BatchNormalization())\n",
        "modeli.add(GlobalAveragePooling1D()) #aka to return_sequences=False\n",
        "modeli.add(RepeatVector(max_out_length)) #conection\n",
        "modeli.add(CuDNNGRU(512, return_sequences=True))\n",
        "modeli.add(TimeDistributed(Dense(n_words_t, activation='softmax')))\n",
        "modeli.compile(optimizer='adam', loss='sparse_categorical_crossentropy', sample_weight_mode='temporal')\n",
        "modeli.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 35, 100)           595500    \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 35, 256)           128256    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 35, 256)           1024      \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 35, 256)           1024      \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 35, 256)           1024      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_3 (RepeatVecto (None, 35, 256)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_6 (CuDNNGRU)       (None, 35, 512)           1182720   \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 35, 8762)          4494906   \n",
            "=================================================================\n",
            "Total params: 7,060,326\n",
            "Trainable params: 7,058,790\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiPVpfUu51GT",
        "colab_type": "code",
        "outputId": "448f81b8-d837-4dc7-8e7a-aec5d5ffab21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "modeli.fit(X_train, Y_train, epochs=20, batch_size=256,validation_data=(X_val, Y_val), sample_weight = sample_weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 115671 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "115671/115671 [==============================] - 76s 655us/step - loss: 4.5896 - val_loss: 13.6316\n",
            "Epoch 2/20\n",
            "115671/115671 [==============================] - 78s 671us/step - loss: 3.2544 - val_loss: 13.3680\n",
            "Epoch 3/20\n",
            "115671/115671 [==============================] - 79s 682us/step - loss: 2.5319 - val_loss: 13.5044\n",
            "Epoch 4/20\n",
            "115671/115671 [==============================] - 79s 684us/step - loss: 2.1046 - val_loss: 13.2607\n",
            "Epoch 5/20\n",
            "115671/115671 [==============================] - 79s 683us/step - loss: 1.8460 - val_loss: 13.2080\n",
            "Epoch 6/20\n",
            "115671/115671 [==============================] - 79s 683us/step - loss: 1.6674 - val_loss: 13.1604\n",
            "Epoch 7/20\n",
            "115671/115671 [==============================] - 79s 682us/step - loss: 1.5349 - val_loss: 13.1054\n",
            "Epoch 8/20\n",
            "115671/115671 [==============================] - 79s 682us/step - loss: 1.4275 - val_loss: 13.2484\n",
            "Epoch 9/20\n",
            "115671/115671 [==============================] - 79s 681us/step - loss: 1.3396 - val_loss: 13.1776\n",
            "Epoch 10/20\n",
            "115671/115671 [==============================] - 79s 681us/step - loss: 1.2646 - val_loss: 13.1898\n",
            "Epoch 11/20\n",
            "115671/115671 [==============================] - 79s 681us/step - loss: 1.1997 - val_loss: 13.1524\n",
            "Epoch 12/20\n",
            "115671/115671 [==============================] - 79s 680us/step - loss: 1.1421 - val_loss: 13.1920\n",
            "Epoch 13/20\n",
            "115671/115671 [==============================] - 79s 680us/step - loss: 1.0918 - val_loss: 13.2114\n",
            "Epoch 14/20\n",
            "115671/115671 [==============================] - 79s 681us/step - loss: 1.0470 - val_loss: 13.1381\n",
            "Epoch 15/20\n",
            "115671/115671 [==============================] - 79s 682us/step - loss: 1.0072 - val_loss: 13.1567\n",
            "Epoch 16/20\n",
            "115671/115671 [==============================] - 79s 682us/step - loss: 0.9766 - val_loss: 13.1086\n",
            "Epoch 17/20\n",
            "115671/115671 [==============================] - 79s 681us/step - loss: 0.9373 - val_loss: 13.2184\n",
            "Epoch 18/20\n",
            "115671/115671 [==============================] - 79s 681us/step - loss: 0.9103 - val_loss: 13.2510\n",
            "Epoch 19/20\n",
            "115671/115671 [==============================] - 79s 681us/step - loss: 0.8782 - val_loss: 13.1117\n",
            "Epoch 20/20\n",
            "115671/115671 [==============================] - 79s 680us/step - loss: 0.8534 - val_loss: 13.1405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1aa7ba0be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryEiHbmnDIsE",
        "colab_type": "code",
        "outputId": "58b3fd38-72d9-4178-f205-f5a0e746eea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"For the convolutional model:\")\n",
        "Y_test_pred = modeli.predict_classes(X_test[idx] )\n",
        "for i, n_sampled in enumerate(idx):\n",
        "    text_input = [idx2word_s[p] for p in predict_words(X_test[n_sampled], data=\"source\")]\n",
        "    print(\"\\nText source: \", ' '.join(text_input))\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_test[n_sampled,:,0], data=\"target\")]\n",
        "    print(\"Text target true: \", ' '.join( text_real))\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_test_pred[i], data=\"target\")]\n",
        "    print(\"Text target predicted: \", ' '.join(text_sampled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the convolutional model:\n",
            "\n",
            "Text source:  will get lower\n",
            "Text target true:  BOS as EOS\n",
            "Text target predicted:  BOS você tentar acalmar EOS\n",
            "\n",
            "Text source:  hes shorter than tom\n",
            "Text target true:  BOS ele é mais baixo do que tom EOS\n",
            "Text target predicted:  BOS ele é mais do do que também EOS\n",
            "\n",
            "Text source:  wait in here\n",
            "Text target true:  BOS espere aqui EOS\n",
            "Text target predicted:  BOS espere aqui aqui EOS\n",
            "\n",
            "Text source:  youre bluffing\n",
            "Text target true:  BOS vocês estão blefando EOS\n",
            "Text target predicted:  BOS você está blefando EOS\n",
            "\n",
            "Text source:  they bought a car\n",
            "Text target true:  BOS eles compraram um carro EOS\n",
            "Text target predicted:  BOS eles compraram um um EOS\n",
            "\n",
            "Text source:  fog has limited to meters\n",
            "Text target true:  BOS o a a metros EOS\n",
            "Text target predicted:  BOS a que tem de EOS\n",
            "\n",
            "Text source:  she said that she was eager to go there\n",
            "Text target true:  BOS ela disse que estava ansiosa para ir lá EOS\n",
            "Text target predicted:  BOS ela disse que estava lá lá de lá lá EOS\n",
            "\n",
            "Text source:  is the of life\n",
            "Text target true:  BOS a variedade é o da vida EOS\n",
            "Text target predicted:  BOS a é de é EOS\n",
            "\n",
            "Text source:  we are looking forward to hearing about your trip\n",
            "Text target true:  BOS estamos esperando ouvir sobre a sua viagem EOS\n",
            "Text target predicted:  BOS estamos estamos ansioso de lhe a a viagem EOS\n",
            "\n",
            "Text source:  stop changing the subject\n",
            "Text target true:  BOS pare de mudar de assunto EOS\n",
            "Text target predicted:  BOS pare de agir de de assunto EOS\n",
            "\n",
            "Text source:  i didnt even know your name\n",
            "Text target true:  BOS eu nem sequer sabia o seu nome EOS\n",
            "Text target predicted:  BOS eu nem sequer sabia o também dela EOS\n",
            "\n",
            "Text source:  tom looked at the sky\n",
            "Text target true:  BOS tom olhou para o céu EOS\n",
            "Text target predicted:  BOS tom olhou para EOS\n",
            "\n",
            "Text source:  tom was waiting over there for you but i dont see him now\n",
            "Text target true:  BOS tom estava esperando por você mas eu não estou vendo ele agora EOS\n",
            "Text target predicted:  BOS tom tom esperando ali esperando pelos agora agora agora agora agora agora agora EOS\n",
            "\n",
            "Text source:  tom didnt show up for work yesterday\n",
            "Text target true:  BOS tom não veio trabalhar ontem EOS\n",
            "Text target predicted:  BOS tom não não ontem ontem ontem ontem EOS\n",
            "\n",
            "Text source:  tom ate his with his salad fork\n",
            "Text target true:  BOS por engano o tomás comeu a entrada com o garfo da salada EOS\n",
            "Text target predicted:  BOS o tom comeu com um de de EOS\n",
            "\n",
            "Text source:  i dont want to hurt your feelings\n",
            "Text target true:  BOS eu não quero ferir os seus sentimentos EOS\n",
            "Text target predicted:  BOS eu quero quero os os os EOS\n",
            "\n",
            "Text source:  if tom had stayed in his hometown he never wouldve met mary\n",
            "Text target true:  BOS se o tom tivesse ficado em sua cidade natal ele nunca teria conhecido a mary EOS\n",
            "Text target predicted:  BOS se tom tom tido uma semana semana semana semana semana se se teria se EOS\n",
            "\n",
            "Text source:  tom was unable to hold a job or live by himself\n",
            "Text target true:  BOS tom era incapaz de se manter num emprego e de viver sozinho EOS\n",
            "Text target predicted:  BOS tom não conseguiu conseguir para trabalho novo agora agora EOS\n",
            "\n",
            "Text source:  you have betrayed us\n",
            "Text target true:  BOS você nos traiu EOS\n",
            "Text target predicted:  BOS você já nos EOS\n",
            "\n",
            "Text source:  have you ever been to\n",
            "Text target true:  BOS você já esteve em EOS\n",
            "Text target predicted:  BOS você já já foi EOS\n",
            "\n",
            "Text source:  id like a hot tea with honey\n",
            "Text target true:  BOS gostaria de um chá quente com mel EOS\n",
            "Text target predicted:  BOS eu de de uma com com com EOS\n",
            "\n",
            "Text source:  toms wife keeps him grounded\n",
            "Text target true:  BOS a esposa do tom o mantém de castigo EOS\n",
            "Text target predicted:  BOS a mulher tom tom grávida de de EOS\n",
            "\n",
            "Text source:  tom did it all\n",
            "Text target true:  BOS tom fez tudo EOS\n",
            "Text target predicted:  BOS tom tom o tudo também EOS\n",
            "\n",
            "Text source:  tom got the job he wanted\n",
            "Text target true:  BOS tom conseguiu o emprego que EOS\n",
            "Text target predicted:  BOS tom fez o trabalho que eu trabalhava EOS\n",
            "\n",
            "Text source:  we need a leader\n",
            "Text target true:  BOS nós precisamos de um líder EOS\n",
            "Text target predicted:  BOS precisamos de um um EOS\n",
            "\n",
            "Text source:  i dont want to make anyone unhappy\n",
            "Text target true:  BOS eu não quero fazer com que ninguém se sinta infeliz EOS\n",
            "Text target predicted:  BOS eu quero quero que isso EOS\n",
            "\n",
            "Text source:  are you finished\n",
            "Text target true:  BOS você terminou EOS\n",
            "Text target predicted:  BOS já terminou de EOS\n",
            "\n",
            "Text source:  get your coat\n",
            "Text target true:  BOS pegue o seu casaco EOS\n",
            "Text target predicted:  BOS tragame o casaco casaco EOS\n",
            "\n",
            "Text source:  whatre you doing in my room\n",
            "Text target true:  BOS o que você está fazendo no meu quarto EOS\n",
            "Text target predicted:  BOS o que você está fazendo em meu quarto EOS\n",
            "\n",
            "Text source:  ill never give you permission to do that\n",
            "Text target true:  BOS nunca te darei permissão para fazer isso EOS\n",
            "Text target predicted:  BOS eu nunca vou te para para para fazer isso isso EOS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeXBTv5_DHXW",
        "colab_type": "text"
      },
      "source": [
        "> j) A pesar de que la tarea de medir qué tan similar es un texto a otro ya es un área de investigación propia [[6]](#refs), usted deberá utilizar alguna métrica de desempeño para ver qué tan buena es la traducción del texto *versus* el texto real entregado. Debido a que la métrica de *Exact Matching* (EM) puede ser muy drástica, mida *f1 score* por texto además de proponer alguna otra técnica de evaluación para medir sobre el conjunto de pruebas y los otros conjuntos si estima conveniente. Puede basarse en otros trabajos como *Image captioning* o *Text summary*. \n",
        "\n",
        "> *Hint: Debido a los problemas de memoria al realizar un forward-pass, solo seleccione un subconjunto $N_{sub}$ del conjunto de pruebas para realizar ésta evaluación, se aconseja entre 1000 y 5000.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noparbaoDnBg",
        "colab_type": "code",
        "outputId": "f8a1e328-2ebd-47d0-8d6a-29ebfbdc152d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "m = MultiLabelBinarizer().fit([np.arange(n_words_t)])\n",
        "\n",
        "def calculate_f1(true, pred):\n",
        "    true = np.squeeze(true)\n",
        "    pred = np.squeeze(pred)\n",
        "    binarized_true = m.transform([predict_words(true)])[0] #onehot of words appear\n",
        "    binarized_pred = m.transform([predict_words(pred)])[0] #onehot of words appear\n",
        "    return f1_score(binarized_true, binarized_pred, average='binary') #only on appearing words\n",
        "  \n",
        "ids = np.random.choice(np.arange(Y_test.shape[0]), size=3000, replace=False)\n",
        "\n",
        "def evaluate_it_f1(ids, model):\n",
        "  Y_true = [Y_test[i] for i in ids]\n",
        "  x_t = np.asarray([X_test[i] for i in ids])\n",
        "\n",
        "  Y_hat = modeli.predict_classes(x_t)\n",
        "\n",
        "  f1_final = np.mean([calculate_f1(true_words,pred_words) for true_words,pred_words in zip(Y_true,Y_hat)])\n",
        "  return f1_final #porcentaje\n",
        "\n",
        "evaluate_it_f1(ids, modeli)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6829066388700148"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKXBoVuKKggy",
        "colab_type": "text"
      },
      "source": [
        ">> La función de *f1 score* en este extracto se calcula en base al *precision* y *recall* de que aparezca cada una de las palabras predichas dentro de las palabras reales (como si cada palabra fuera una clase de \"aparece\" o no), **sin importar el orden ni la ocurrencia**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5JQhy87LGNY",
        "colab_type": "text"
      },
      "source": [
        "> k) En ves de volver a variar el modelo de *Encoder*, dejaremos una representación manual explícita (*no entrenable*) a través de extraer características manuales de los textos *source*, como por ejemplo representaciones *term frequency* (TF) o TF-IDF, proporcionadas a través de __[sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text)__. Luego, con esto generado, defina y entrene el modelo *Decoder* neuronal como el presentado en las preguntas anteriores, ésto es comenzar desde la capa *RepeatVector* hasta llegar a la clasificación sobre el texto *target*. Compare el desempeño con lo presentado en (j) y lo visualizado en (h)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPRDAtEtFp8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "def dummy_fun(doc):\n",
        "    return doc\n",
        "tf_idf = TfidfVectorizer(analyzer='word',tokenizer=dummy_fun,preprocessor=dummy_fun,\n",
        "                         token_pattern=None,use_idf= True, smooth_idf=True, norm='l2')   \n",
        "X_train_tfidf = tf_idf.fit_transform(dataX_train).astype('float32').todense()\n",
        "X_val_tfidf = tf_idf.fit_transform(dataX_val).astype('float32').todense()\n",
        "X_test_tfidf = tf_idf.fit_transform(dataX_test).astype('float32').todense()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKauxdgkMpEY",
        "colab_type": "code",
        "outputId": "17b6ac5c-bcef-4b27-a04e-ad1c1a940121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train_tfidf.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(115671, 5954)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyLDyMO4LsAe",
        "colab_type": "code",
        "outputId": "d4b2ec2b-2fd5-4712-fdd8-ba9e0c4679d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "from keras.layers import InputLayer\n",
        "\n",
        "modelf = Sequential()\n",
        "\n",
        "modelf.add(RepeatVector(max_out_length)) #conection\n",
        "modelf.add(CuDNNGRU(512, return_sequences=True))\n",
        "modelf.add(TimeDistributed(Dense(n_words_t, activation='softmax')))\n",
        "modelf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', sample_weight_mode='temporal')\n",
        "modelf.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-66ea96e03e37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodelf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodelf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5954\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodelf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepeatVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_out_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#conection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodelf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCuDNNGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodelf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_words_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'InputLayer' is not defined"
          ]
        }
      ]
    }
  ]
}