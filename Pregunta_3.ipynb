{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 995,
     "status": "ok",
     "timestamp": 1560880251043,
     "user": {
      "displayName": "Andres Huerta",
      "photoUrl": "",
      "userId": "03241462261896548486"
     },
     "user_tz": 240
    },
    "id": "BH5qICi2jb5y",
    "outputId": "9922c460-2517-4104-e178-641fbebfb290"
   },
   "outputs": [],
   "source": [
    "#csv desde drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HuoKOpHl0XY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_J8_BgJNjrwx"
   },
   "source": [
    "## 3. *Encoder-Decoder* sobre Texto\n",
    "\n",
    "Trabajos recientes en redes neuronales han demostrado que se puede aplicar a problemas bastante complejos gracias a la flexibilidad la definición de las redes, además de que se pueden adaptar a distintos tipos de datos brutos (dominios). Con el objetivo de explorar el enfoque anterior de *traducción* de algun tipo de dato, en esta sección deberá realizarlo con texto para traducción de un lenguaje humano a otro (e.g. inglés a alemán, chino a ruso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3bpddwLRlmkR"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./por.txt\", sep=\"\\t\", names=[\"Source\",\"Target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18ov-iPJl81p"
   },
   "source": [
    "> a) Visualice los datos ¿Qué es la entrada y qué es la salida? Comente sobre los múltiples significados/sinónimos que puede tener una palabra al ser traducida y cómo propondría arreglar eso. *se espera que pueda implementarlo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1678,
     "status": "ok",
     "timestamp": 1560880251759,
     "user": {
      "displayName": "Andres Huerta",
      "photoUrl": "",
      "userId": "03241462261896548486"
     },
     "user_tz": 240
    },
    "id": "bxMZv99Cl3Ik",
    "outputId": "4342002d-d4b6-4a38-ab08-6d88ed256a9e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vai.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vá.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Oi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corre!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corra!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corram!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Run.</td>\n",
       "      <td>Corre!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Run.</td>\n",
       "      <td>Corra!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Run.</td>\n",
       "      <td>Corram!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Quem?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source   Target\n",
       "0    Go.     Vai.\n",
       "1    Go.      Vá.\n",
       "2    Hi.      Oi.\n",
       "3   Run!   Corre!\n",
       "4   Run!   Corra!\n",
       "5   Run!  Corram!\n",
       "6   Run.   Corre!\n",
       "7   Run.   Corra!\n",
       "8   Run.  Corram!\n",
       "9   Who?    Quem?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1JBeAONma4h"
   },
   "source": [
    "La entrada del dataset corresponde a la frase o palabra escrita en ingles y el objetivo o salida corresponde a la traducción de lo anterior al idioma que se desea trabajar, en este caso portugues.\n",
    "\n",
    "Al inicio del dataset se pueden ver unicamente palabras junto con su traducción explicita, se puede notar ademas que existen palabras repetidas en ingles que se traducen de una manera distinta, esto se debe a que el ingles no posee una conjugación explicita en la palabra como es el caso del español o el portuges, sino que se le da un contexto con el resto de la oración. Se espera que el encoder tenga problemas al traducir frases con dichas palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1668,
     "status": "ok",
     "timestamp": 1560880251759,
     "user": {
      "displayName": "Andres Huerta",
      "photoUrl": "",
      "userId": "03241462261896548486"
     },
     "user_tz": 240
    },
    "id": "62DwDH0MmX2K",
    "outputId": "e110dffb-e60d-4938-dbc9-8a90f741b295"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135666</th>\n",
       "      <td>The Tatoeba Project, which can be found online...</td>\n",
       "      <td>O Projeto Tatoeba, que se pode encontrar on-li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135667</th>\n",
       "      <td>No matter how much you try to convince people ...</td>\n",
       "      <td>Não importa o quanto você tenta convencer os o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135668</th>\n",
       "      <td>Some movies make such an impact that one never...</td>\n",
       "      <td>Alguns filmes são tão marcantes que jamais nos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135669</th>\n",
       "      <td>A child who is a native speaker usually knows ...</td>\n",
       "      <td>Uma criança que é falante nativa geralmente sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135670</th>\n",
       "      <td>We recommend adding sentences and translations...</td>\n",
       "      <td>Recomendamos acrescentar frases e traduções na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Source  \\\n",
       "135666  The Tatoeba Project, which can be found online...   \n",
       "135667  No matter how much you try to convince people ...   \n",
       "135668  Some movies make such an impact that one never...   \n",
       "135669  A child who is a native speaker usually knows ...   \n",
       "135670  We recommend adding sentences and translations...   \n",
       "\n",
       "                                                   Target  \n",
       "135666  O Projeto Tatoeba, que se pode encontrar on-li...  \n",
       "135667  Não importa o quanto você tenta convencer os o...  \n",
       "135668  Alguns filmes são tão marcantes que jamais nos...  \n",
       "135669  Uma criança que é falante nativa geralmente sa...  \n",
       "135670  Recomendamos acrescentar frases e traduções na...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTyPtK2wmMPc"
   },
   "source": [
    "Cuando se analizan los datos al final del conjunto se puede ver que ya se esta trabajando con oraciones y no unicamente con palabras simples, se espera que estos ejemplos permitan a la red neuronal aprender a reconocer un poco el contexto en el cual se esta utilizando la palabra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlJXIT1pnu4Q"
   },
   "source": [
    "> b) Realice un pre-procesamiento a los textos como se acostumbra para eliminar símbolos inecesarios u otras cosas que estime conveniente, comente sobre la importancia de éste paso. Además de ésto deberá agregar un símbolo al final de la sentencia *target* para indicar un \"alto\" cuando la red neuronal necesite aprender a generar una sentencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZqprTLpl3LV"
   },
   "outputs": [],
   "source": [
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def clean_text(text, where=None):\n",
    "    \"\"\" OJO: Sin eliminar el significado de las palabras.\"\"\"\n",
    "    text = text.lower()\n",
    "    tokenize_text = text.split()\n",
    "    tokenize_text = [word.translate(table) for word in tokenize_text]#eliminar puntuacion\n",
    "    tokenize_text = [word for word in tokenize_text if word.isalpha()] #remove numbers\n",
    "    if where ==\"target\":\n",
    "        tokenize_text = tokenize_text + [\"#anvorgesa\"] \n",
    "    return tokenize_text\n",
    "\n",
    "  \n",
    "texts_input = list(df['Source'].apply(clean_text))\n",
    "texts_output = list(df['Target'].apply(clean_text, where='target'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Uq4O2NcoR9U"
   },
   "source": [
    "> Cree un conjunto de validación y de pruebas fijos de $N_{exp} = 10000$ datos ¿Cuántos datos quedan para entrenar? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFsSmWJ9ogst"
   },
   "outputs": [],
   "source": [
    "N_exp = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiYlkP23l3OW"
   },
   "outputs": [],
   "source": [
    "X_train_l, X_test_l, Y_train_l, Y_test_l = train_test_split(texts_input, texts_output,\n",
    "                                                            test_size=N_exp, random_state=22)\n",
    "X_train_l, X_val_l, Y_train_l, Y_val_l = train_test_split(X_train_l, Y_train_l, \n",
    "                                                          test_size=N_exp, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3440,
     "status": "ok",
     "timestamp": 1560880253570,
     "user": {
      "displayName": "Andres Huerta",
      "photoUrl": "",
      "userId": "03241462261896548486"
     },
     "user_tz": 240
    },
    "id": "jWt6PF1El3Qs",
    "outputId": "0cf3e195-461e-4e8c-c5be-bd58ee05879c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115671"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Nj5BGP0otYS"
   },
   "source": [
    "Luego de haber generado el cconjunto de testing y validación aún quedan 115671 ejemplos para entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRwaQUY4o52h"
   },
   "source": [
    "> *Recuerde que si no puede procesar los datos de entrenamiento adecuadamente siempre puede muestrear en base a la capacidad de cómputo que posea*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yWv7nkZEo8vo"
   },
   "source": [
    "> c) Genere un vocabulario, **desde el conjunto de entrenamiento**, sobre las palabras a recibir y generar en la traducción, esto es codificarlas a un valor entero que servirá para que la red las vea en una representación útil a procesar, *comience desde el 1 debido a que el cero será utilizado más adelante*. Para reducir el vocabulario considere las palabras que aparecen un mínimo de *min_count* veces en todo los datos, se aconseja un valor de 3. Comente sobre la importancia de ésto al reducir el vocabulario ¿De qué tamaño es el vocabulario de entrada y salida? ¿La diferencia de ésto podría ser un factor importante?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hn54Zioel3Te"
   },
   "outputs": [],
   "source": [
    "def create_vocab(texts, min_count=1):\n",
    "    count_vocab = {}\n",
    "    for sentence in texts:\n",
    "        for word in sentence:\n",
    "            if word not in count_vocab:\n",
    "                count_vocab[word] = 1\n",
    "            else:\n",
    "                count_vocab[word] += 1\n",
    "    return [word for word,count in count_vocab.items() if count >= min_count]\n",
    "  \n",
    "vocab_source = create_vocab(X_train_l, min_count=3)\n",
    "word2idx_s = {w: i+1 for i, w in enumerate(vocab_source)} #index (i+1) start from 1,2,3,...\n",
    "idx2word_s = {i+1: w for i, w in enumerate(vocab_source)}\n",
    "n_words_s = len(vocab_source)\n",
    "vocab_target = create_vocab(Y_train_l, min_count=3)\n",
    "word2idx_t = {w: i+1 for i, w in enumerate(vocab_target)}  #Converting text to numbers\n",
    "idx2word_t = {i+1: w for i, w in enumerate(vocab_target)}\n",
    "n_words_t = len(vocab_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cizs2bRqpyxK"
   },
   "source": [
    "Dado que existe una gran cantidad de palabras dentro del vocabulario y la memoria del sistema que se utilice no es ilimitada es necesario reducir el tamaño para poder trabajar con el dataset, ademas palabras que aparescan menos de una determinada cantidad de veces pueden considerarse como poco relevantes para la traducción del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4313,
     "status": "ok",
     "timestamp": 1560880254466,
     "user": {
      "displayName": "Andres Huerta",
      "photoUrl": "",
      "userId": "03241462261896548486"
     },
     "user_tz": 240
    },
    "id": "47NOdPeWpt7d",
    "outputId": "63d93e6c-501f-4fb7-deaf-0e8b74b11fed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de palabras en origen: 5954\n",
      "\n",
      "Tamaño de palabras en destino 8760\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño de palabras en origen:\",n_words_s)\n",
    "print(\"\\nTamaño de palabras en destino\",n_words_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qonri4Saprhl"
   },
   "source": [
    "El tamaño del conjunto de palabras de origen es de 5954 palabras, mientras que el destino es de 8760, esto se debe a lo comentado anteriormente referenciando a que el ingles obtiene la conjugación de una palabra en base al contexto en el cual se esta hablando y no explicitamente en la forma en que se escribe.\n",
    "\n",
    "Esto, en opinión propia, puede afectar negativamente a la red, puesto que sin el contexto adecuado una red podría traducir una palabra de multiples maneras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJDsAJkArZMK"
   },
   "source": [
    "> Ahora codifique las palabras a los números indexados con el vocabulario. Recuerde que si una palabra en los otros conjuntos, o en el mismo de entrenamiento, no aparece en el vocabulario no se podrá generar una codificación, por lo que será **ignorada** ¿Cómo se podría evitar ésto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6nzVB-Ol3WJ"
   },
   "outputs": [],
   "source": [
    "\"\"\" Source/input data \"\"\"\n",
    "dataX_train = [[word2idx_s[word] for word in sent if word in word2idx_s] for sent in X_train_l]\n",
    "dataX_val = [[word2idx_s[word] for word in sent if word in word2idx_s] for sent in X_val_l]\n",
    "dataX_test = [[word2idx_s[word] for word in sent if word in word2idx_s] for sent in X_test_l]\n",
    "\n",
    "\"\"\" Target/output data \"\"\"\n",
    "dataY_train = [[word2idx_t[word] for word in sent if word in word2idx_t] for sent in Y_train_l]\n",
    "dataY_val = [[word2idx_t[word] for word in sent if word in word2idx_t] for sent in Y_val_l] \n",
    "dataY_test = [[word2idx_t[word] for word in sent if word in word2idx_t] for sent in Y_test_l] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XRY-QiBsSXA"
   },
   "source": [
    "> d) Debido al largo variable de los textos de entrada y salida será necesario estandarizar ésto para poder trabajar de manera más cómoda en Keras, *cada texto (entrada y salida) pueden tener distinto largo máximo*. Comente sobre la decisión del tipo de *padding*, *pre o post* ¿Qué sucede al variar el largo máximo de instantes de tiempo para procesar en cada parte del modelo (entrada y salida)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1830,
     "status": "ok",
     "timestamp": 1560880269088,
     "user": {
      "displayName": "Andres Huerta",
      "photoUrl": "",
      "userId": "03241462261896548486"
     },
     "user_tz": 240
    },
    "id": "F5BdzJFml3Ys",
    "outputId": "be20568f-b21f-467e-ea9b-911c77e99e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largo max inp:  35\n",
      "Largo max out:  34\n"
     ]
    }
   ],
   "source": [
    "\"\"\" INPUT DATA (Origin language) \"\"\"\n",
    "max_inp_length = max([max(map(len,dataX_train)), max(map(len,dataX_val)), max(map(len,dataX_test))])\n",
    "print(\"Largo max inp: \",max_inp_length)\n",
    "word2idx_s[\"#anvorgesa\"] = 0 #padding symbol\n",
    "idx2word_s[0] = \"#anvorgesa\"\n",
    "n_words_s += 1  \n",
    "X_train = sequence.pad_sequences(dataX_train, maxlen=max_inp_length, padding='post', value=word2idx_s[\"#anvorgesa\"])\n",
    "X_val = sequence.pad_sequences(dataX_val, maxlen=max_inp_length, padding='post', value=word2idx_s[\"#anvorgesa\"])\n",
    "X_test = sequence.pad_sequences(dataX_test, maxlen=max_inp_length, padding='post', value=word2idx_s[\"#anvorgesa\"])\n",
    "\n",
    "\"\"\" OUTPUT DATA (Destination language) \"\"\"\n",
    "max_out_length = max([max(map(len,dataY_train)), max(map(len,dataY_val)), max(map(len,dataY_test))])\n",
    "print(\"Largo max out: \",max_out_length)\n",
    "word2idx_t[\"#anvorgesa\"] = 0 #padding symbol\n",
    "idx2word_t[0] = \"#anvorgesa\"\n",
    "n_words_t += 1  \n",
    "Y_train = sequence.pad_sequences(dataY_train, maxlen=max_out_length, padding='post', value=word2idx_t[\"#anvorgesa\"])\n",
    "Y_val = sequence.pad_sequences(dataY_val, maxlen=max_out_length, padding='post', value=word2idx_t[\"#anvorgesa\"])\n",
    "Y_test = sequence.pad_sequences(dataY_test, maxlen=max_out_length, padding='post', value=word2idx_t[\"#anvorgesa\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZFSKSmxStx06"
   },
   "source": [
    "> e) Para evitar que la red obtenga una ganancia por imitar/predecir el símbolo de *padding* que está bastante presente en los datos coloque un peso sobre éste clase, con valor 0, así se evita que tenga impacto en la función objetivo. Ya que *keras* no soporta directamente ésto en series de tiempo coloque el peso a cada instante de tiempo de cada dato de entrenamiento dependiendo de su clase. Comente sobre alguna otra forma en que se podría manejar el evitar que la red prediga en mayoría el símbolo de *padding*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vB0zWIozl3bi"
   },
   "outputs": [],
   "source": [
    "c_weights = np.ones(n_words_t)\n",
    "c_weights[0] = 0 #padding class masked\n",
    "sample_weight = np.zeros(Y_train.shape)\n",
    "for i in range(sample_weight.shape[0]):\n",
    "    sample_weight[i] = c_weights[Y_train[i,:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> f) Para lograr la tarea defina una red recurrente del tipo *encoder*-*decoder* como la que se presenta en la siguiente imágen.\n",
    "<img src=\"https://chunml.github.io/ChunML.github.io/images/projects/sequence-to-sequence/repeated_vector.png\" width=\"60%\" />\n",
    "En primer lugar defina el *Encoder* que procesara el texto de entrada y retornará un solo vector final, haciendo uso de las capas ya conocidas de *Embedding* para generar un vector denso de palabra y *GRU*, pero en su versión acelerada para GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/andres/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,CuDNNGRU, GRU\n",
    "EMBEDDING_DIM = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_words_s, output_dim=EMBEDDING_DIM, input_length=max_inp_length))\n",
    "#model.add(CuDNNGRU(64, return_sequences=True))\n",
    "#model.add(CuDNNGRU(128, return_sequences=False))\n",
    "model.add(GRU(64, return_sequences=True))\n",
    "model.add(GRU(128, return_sequences=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Luego defina la sección que conecta el largo (*timesteps*) de entrada *vs* el de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import RepeatVector\n",
    "model.add(RepeatVector(max_out_length)) #conection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente defina el *Decoder* para generar la secuencia de salida en texto de palabras en otro idioma, a través de la función *softmax* sobre cada instante de tiempo (*timestep*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 35, 100)           595500    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 35, 64)            31680     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               74112     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 34, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 34, 64)            37056     \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 34, 128)           74112     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 34, 8761)          1130169   \n",
      "=================================================================\n",
      "Total params: 1,942,629\n",
      "Trainable params: 1,942,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU, TimeDistributed,Dense\n",
    "#model.add(CuDNNGRU(128, return_sequences=True))\n",
    "#model.add(CuDNNGRU(64, return_sequences=True))\n",
    "model.add(GRU(64, return_sequences=True))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_words_t, activation='softmax')))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Entrene la red entre 1 a 5 *epochs*, agregando los pesos definidos sobre cada ejemplo de entrenamiento. Además de utilizar una función de pérdida que evita generar explícitamente los *one hot vector*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de entrenar es necesario cambiar la forma del input y output a 3 dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115671, 34, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.reshape(Y_train, (Y_train.shape[0], max_out_length, 1))\n",
    "Y_val = np.reshape(Y_val, (Y_val.shape[0], max_out_length, 1))\n",
    "Y_test = np.reshape(Y_test, (Y_test.shape[0], max_out_length, 1))\n",
    "\n",
    "Y_train.shape\n",
    "#X_test = np.reshape(X_test, (X_test.shape[0], lstm_num_timesteps, lstm_num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/andres/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 115671 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "115671/115671 [==============================] - 1911s 17ms/step - loss: 5.8284 - val_loss: 13.5294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f00c75e7e10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', sample_weight_mode='temporal')\n",
    "model.fit(X_train, Y_train, epochs=1, batch_size=256,validation_data=(X_val, Y_val), sample_weight = sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./modell.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Pregunta_2_ann_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
